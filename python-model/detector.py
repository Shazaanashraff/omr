# -*- coding: utf-8 -*-
"""final dl omr

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18PBDSZ_5LwY6qCGkFuBrQu-ndXAbC4Bu
"""

try:
    from google.colab import drive
except ImportError:
    drive = None

import cv2
import numpy as np
from typing import List, Tuple, Dict
import matplotlib.pyplot as plt

class OMRDetector:
    def __init__(self):
        self.marking_threshold = 0.3

    def preprocess_image(self, image_path: str) -> np.ndarray:
        """
        Preprocess the OMR sheet image for better detection
        """

        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Could not read image from {image_path}")


        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)


        blurred = cv2.GaussianBlur(gray, (3, 3), 0)


        thresh = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3
        )


        kernel = np.ones((2,2), np.uint8)
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

        return img, gray, thresh

    def detect_grid_structure(self, thresh: np.ndarray) -> Tuple[List, List]:
        """
        Detect horizontal and vertical lines to identify grid structure
        """

        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))


        horizontal_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel)


        vertical_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel)

        return horizontal_lines, vertical_lines

    def find_circles(self, gray: np.ndarray) -> List[Tuple[int, int, int]]:
        """
        Detect circles (answer bubbles) in the image using HoughCircles
        """
        circles = cv2.HoughCircles(
            gray,
            cv2.HOUGH_GRADIENT,
            dp=1,
            minDist=25,
            param1=50,
            param2=35,
            minRadius=10,
            maxRadius=30
        )

        if circles is not None:
            circles = np.round(circles[0, :]).astype("int")
            return [(x, y, r) for x, y, r in circles]
        return []

    def create_bounding_boxes(self, circles: List[Tuple[int, int, int]],
                            image_shape: Tuple[int, int]) -> Dict:
        """
        Create bounding boxes for questions and options based on detected circles
        Now handles batch structure: 1-10, 11-20, 21-30, 31-40
        """
        if not circles:
            return {}


        filtered_circles = []
        for x, y, r in circles:

            if 8 <= r <= 30:
                filtered_circles.append((x, y, r))

        print(f"Filtered to {len(filtered_circles)} potential answer bubbles")


        circles_sorted = sorted(filtered_circles, key=lambda c: (c[1], c[0]))


        rows = []
        current_row = []
        row_tolerance = 35

        for circle in circles_sorted:
            x, y, r = circle
            if not current_row or abs(y - current_row[-1][1]) <= row_tolerance:
                current_row.append(circle)
            else:
                if current_row and len(current_row) >= 4:

                    sorted_row = sorted(current_row, key=lambda c: c[0])

                    for i in range(0, len(sorted_row), 4):
                        group = sorted_row[i:i+4]
                        if len(group) >= 4:
                            rows.append(group[:4])
                current_row = [circle]


        if current_row and len(current_row) >= 4:
            sorted_row = sorted(current_row, key=lambda c: c[0])
            for i in range(0, len(sorted_row), 4):
                group = sorted_row[i:i+4]
                if len(group) >= 4:
                    rows.append(group[:4])

        print(f"Found {len(rows)} complete question rows")



        rows_with_x = [(min(row, key=lambda c: c[0])[0], row) for row in rows]
        rows_with_x.sort(key=lambda item: item[0])


        columns = [[], [], [], []]
        if rows_with_x:

            x_positions = [item[0] for item in rows_with_x]
            img_width = image_shape[1]
            col_width = img_width // 4

            for x_pos, row in rows_with_x:
                col_idx = min(3, max(0, int(x_pos // col_width)))
                columns[col_idx].append(row)


        bounding_boxes = {}

        for col_idx, column in enumerate(columns):
            if not column:
                continue


            column_sorted = sorted(column, key=lambda row: min(row, key=lambda c: c[1])[1])

            print(f"Column {col_idx+1}: Found {len(column_sorted)} questions")

            base_question_number = col_idx * 10 + 1  # 1, 11, 21, 31

            for row_idx, row in enumerate(column_sorted):
                question_number = base_question_number + row_idx
                if question_number > 40:
                    break

                question_key = f"Q{question_number}"


                options = {}
                option_labels = ['A', 'B', 'C', 'D']

                for opt_idx, (x, y, r) in enumerate(row):
                    if opt_idx < len(option_labels):
                        options[option_labels[opt_idx]] = {
                            'bbox': (x - r - 5, y - r - 5, 2*r + 10, 2*r + 10),
                            'center': (x, y),
                            'radius': r
                        }

                bounding_boxes[question_key] = options

        return bounding_boxes

    def analyze_marking(self, gray: np.ndarray, bounding_boxes: Dict) -> Dict:
        """
        Analyze marking intensity in each bounding box to determine if it's marked
        """
        results = {}

        for question, options in bounding_boxes.items():
            question_results = {}

            for option, data in options.items():
                x, y, w, h = data['bbox']
                cx, cy = data['center']
                r = data['radius']


                roi = gray[y:y+h, x:x+w]


                mask = np.zeros((h, w), dtype=np.uint8)
                cv2.circle(mask, (w//2, h//2), r-2, 255, -1)


                masked_roi = cv2.bitwise_and(roi, roi, mask=mask)
                non_zero_pixels = cv2.countNonZero(mask)

                if non_zero_pixels > 0:

                    avg_intensity = np.sum(masked_roi) / non_zero_pixels
                    marking_intensity = 1.0 - (avg_intensity / 255.0)


                    is_marked = marking_intensity > self.marking_threshold
                    confidence = marking_intensity

                    question_results[option] = {
                        'marked': is_marked,
                        'confidence': confidence,
                        'intensity': marking_intensity,
                        'threshold_status': 'high' if marking_intensity > self.marking_threshold else 'low'
                    }

            results[question] = question_results

        return results

    def visualize_results(self, img: np.ndarray, bounding_boxes: Dict,
                         results: Dict) -> np.ndarray:
        """
        Visualize detected bounding boxes and marking results
        """
        vis_img = img.copy()

        for question, options in bounding_boxes.items():
            for option, data in options.items():
                x, y, w, h = data['bbox']
                cx, cy = data['center']
                r = data['radius']


                if question in results and option in results[question]:
                    result = results[question][option]
                    is_marked = result['marked']
                    confidence = result['confidence']


                    color = (0, 255, 0) if is_marked else (0, 0, 255)
                    thickness = 3 if is_marked else 1


                    cv2.rectangle(vis_img, (x, y), (x+w, y+h), color, thickness)


                    cv2.circle(vis_img, (cx, cy), r, color, thickness)


                    label = f"{question}-{option}: {confidence:.2f}"
                    cv2.putText(vis_img, label, (x, y-10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

        return vis_img

    def process_omr_sheet(self, image_path: str) -> Tuple[Dict, Dict, np.ndarray]:
        """
        Complete OMR processing pipeline
        """

        img, gray, thresh = self.preprocess_image(image_path)


        circles = self.find_circles(gray)
        print(f"Detected {len(circles)} circles")


        bounding_boxes = self.create_bounding_boxes(circles, gray.shape)
        print(f"Created bounding boxes for {len(bounding_boxes)} questions")


        results = self.analyze_marking(gray, bounding_boxes)


        vis_img = self.visualize_results(img, bounding_boxes, results)

        return bounding_boxes, results, vis_img

    def print_results(self, results: Dict):
        """
        Print analysis results in a readable format, organized by batches
        """
        print("\n" + "="*60)
        print("OMR ANALYSIS RESULTS (Organized by Batches)")
        print("="*60)


        sorted_questions = sorted(results.keys(), key=lambda x: int(x[1:]))


        batches = {
            "1-10": [],
            "11-20": [],
            "21-30": [],
            "31-40": []
        }

        for question in sorted_questions:
            q_num = int(question[1:])
            if 1 <= q_num <= 10:
                batches["1-10"].append(question)
            elif 11 <= q_num <= 20:
                batches["11-20"].append(question)
            elif 21 <= q_num <= 30:
                batches["21-30"].append(question)
            elif 31 <= q_num <= 40:
                batches["31-40"].append(question)


        for batch_name, questions in batches.items():
            if questions:
                print(f"\n{'='*20} BATCH {batch_name} {'='*20}")

                for question in questions:
                    options = results[question]
                    print(f"\n{question}:")
                    marked_options = []

                    for option, data in options.items():
                        status = "✓ MARKED" if data['marked'] else "✗ unmarked"
                        intensity = data['intensity']
                        threshold_status = data['threshold_status']

                        print(f"  {option}: {status} (intensity: {intensity:.3f}, threshold: {threshold_status})")

                        if data['marked']:
                            marked_options.append(option)

                    if marked_options:
                        print(f"  → Answer(s): {', '.join(marked_options)}")
                    else:
                        print(f"  → No answer detected")

    def get_answer_summary(self, results: Dict) -> Dict:
        """
        Get a clean summary of all answers
        """
        summary = {}


        sorted_questions = sorted(results.keys(), key=lambda x: int(x[1:]))

        for question in sorted_questions:
            options = results[question]
            marked_options = [opt for opt, data in options.items() if data['marked']]

            if marked_options:
                summary[question] = marked_options[0] if len(marked_options) == 1 else marked_options
            else:
                summary[question] = "No Answer"

        return summary


def main():

    detector = OMRDetector()


    detector.marking_threshold = 0.3


    image_path = "/content/IMG-20250803-WA0015.jpg"


    try:
        bounding_boxes, results, visualization = detector.process_omr_sheet(image_path)


        detector.print_results(results)

        print("\n" + "="*40)
        print("ANSWER SUMMARY")
        print("="*40)
        summary = detector.get_answer_summary(results)
        for question, answer in summary.items():
            print(f"{question}: {answer}")




        cv2.imwrite("omr_batch_results.jpg", visualization)
        print(f"\nVisualization saved as 'omr_batch_results.jpg'")


        with open("omr_results.txt", "w") as f:
            f.write("OMR Analysis Results\n")
            f.write("="*50 + "\n\n")
            for question, answer in summary.items():
                f.write(f"{question}: {answer}\n")

        print("Results saved as 'omr_results.txt'")

    except Exception as e:
        print(f"Error processing OMR sheet: {e}")
        print("Please check:")
        print("1. Image path is correct")
        print("2. Image file exists and is readable")
        print("3. Image contains clear circular answer bubbles")

if __name__ == "__main__":
    main()

import cv2
import numpy as np
from typing import List, Tuple, Dict
import matplotlib.pyplot as plt

class OMRDetector:
    def __init__(self):
        self.marking_threshold = 0.3

    def preprocess_image(self, image_path: str) -> np.ndarray:
        """
        Preprocess the OMR sheet image for better detection
        """

        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Could not read image from {image_path}")

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)


        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        thresh = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3
        )

        kernel = np.ones((2,2), np.uint8)
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

        return img, gray, thresh

    def detect_grid_structure(self, thresh: np.ndarray) -> Tuple[List, List]:
        """
        Detect horizontal and vertical lines to identify grid structure
        """

        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))


        horizontal_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel)


        vertical_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel)

        return horizontal_lines, vertical_lines

    def find_circles(self, gray: np.ndarray) -> List[Tuple[int, int, int]]:
        """
        Detect circles (answer bubbles) in the image using HoughCircles
        """
        circles = cv2.HoughCircles(
            gray,
            cv2.HOUGH_GRADIENT,
            dp=1,
            minDist=25,
            param1=50,
            param2=35,
            minRadius=10,
            maxRadius=30
        )

        if circles is not None:
            circles = np.round(circles[0, :]).astype("int")
            return [(x, y, r) for x, y, r in circles]
        return []

    def create_bounding_boxes(self, circles: List[Tuple[int, int, int]],
                            image_shape: Tuple[int, int]) -> Dict:
        """
        Create bounding boxes for questions and options based on detected circles
        Now handles batch structure: 1-10, 11-20, 21-30, 31-40
        """
        if not circles:
            return {}


        filtered_circles = []
        for x, y, r in circles:
            if 8 <= r <= 30:
                filtered_circles.append((x, y, r))

        print(f"Filtered to {len(filtered_circles)} potential answer bubbles")


        circles_sorted = sorted(filtered_circles, key=lambda c: (c[1], c[0]))

        rows = []
        current_row = []
        row_tolerance = 35

        for circle in circles_sorted:
            x, y, r = circle
            if not current_row or abs(y - current_row[-1][1]) <= row_tolerance:
                current_row.append(circle)
            else:
                if current_row and len(current_row) >= 4:
                    sorted_row = sorted(current_row, key=lambda c: c[0])
                    for i in range(0, len(sorted_row), 4):
                        group = sorted_row[i:i+4]
                        if len(group) >= 4:
                            rows.append(group[:4])
                current_row = [circle]


        if current_row and len(current_row) >= 4:
            sorted_row = sorted(current_row, key=lambda c: c[0])
            for i in range(0, len(sorted_row), 4):
                group = sorted_row[i:i+4]
                if len(group) >= 4:
                    rows.append(group[:4])

        print(f"Found {len(rows)} complete question rows")


        rows_with_x = [(min(row, key=lambda c: c[0])[0], row) for row in rows]
        rows_with_x.sort(key=lambda item: item[0])


        columns = [[], [], [], []]
        if rows_with_x:
            x_positions = [item[0] for item in rows_with_x]
            img_width = image_shape[1]
            col_width = img_width // 4

            for x_pos, row in rows_with_x:
                col_idx = min(3, max(0, int(x_pos // col_width)))
                columns[col_idx].append(row)

        bounding_boxes = {}

        for col_idx, column in enumerate(columns):
            if not column:
                continue

            column_sorted = sorted(column, key=lambda row: min(row, key=lambda c: c[1])[1])

            print(f"Column {col_idx+1}: Found {len(column_sorted)} questions")

            base_question_number = col_idx * 10 + 1  # 1, 11, 21, 31

            for row_idx, row in enumerate(column_sorted):
                question_number = base_question_number + row_idx
                if question_number > 40:
                    break

                question_key = f"Q{question_number}"


                options = {}
                option_labels = ['A', 'B', 'C', 'D']

                for opt_idx, (x, y, r) in enumerate(row):
                    if opt_idx < len(option_labels):
                        options[option_labels[opt_idx]] = {
                            'bbox': (x - r - 5, y - r - 5, 2*r + 10, 2*r + 10),
                            'center': (x, y),
                            'radius': r
                        }

                bounding_boxes[question_key] = options

        return bounding_boxes

    def analyze_marking(self, gray: np.ndarray, bounding_boxes: Dict) -> Dict:
        """
        Analyze marking intensity in each bounding box to determine if it's marked
        """
        results = {}

        for question, options in bounding_boxes.items():
            question_results = {}

            for option, data in options.items():
                x, y, w, h = data['bbox']
                cx, cy = data['center']
                r = data['radius']


                roi = gray[y:y+h, x:x+w]


                mask = np.zeros((h, w), dtype=np.uint8)
                cv2.circle(mask, (w//2, h//2), r-2, 255, -1)


                masked_roi = cv2.bitwise_and(roi, roi, mask=mask)
                non_zero_pixels = cv2.countNonZero(mask)

                if non_zero_pixels > 0:
                    avg_intensity = np.sum(masked_roi) / non_zero_pixels
                    marking_intensity = 1.0 - (avg_intensity / 255.0)


                    is_marked = marking_intensity > self.marking_threshold
                    confidence = marking_intensity

                    question_results[option] = {
                        'marked': is_marked,
                        'confidence': confidence,
                        'intensity': marking_intensity,
                        'threshold_status': 'high' if marking_intensity > self.marking_threshold else 'low'
                    }

            results[question] = question_results

        return results

    def visualize_results(self, img: np.ndarray, bounding_boxes: Dict,
                         results: Dict) -> np.ndarray:
        """
        Visualize detected bounding boxes and marking results
        """
        vis_img = img.copy()

        for question, options in bounding_boxes.items():
            for option, data in options.items():
                x, y, w, h = data['bbox']
                cx, cy = data['center']
                r = data['radius']


                if question in results and option in results[question]:
                    result = results[question][option]
                    is_marked = result['marked']
                    confidence = result['confidence']


                    color = (0, 255, 0) if is_marked else (0, 0, 255)
                    thickness = 3 if is_marked else 1


                    cv2.rectangle(vis_img, (x, y), (x+w, y+h), color, thickness)


                    cv2.circle(vis_img, (cx, cy), r, color, thickness)


                    label = f"{question}-{option}: {confidence:.2f}"
                    cv2.putText(vis_img, label, (x, y-10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

        return vis_img

    def process_omr_sheet(self, image_path: str) -> Tuple[Dict, Dict, np.ndarray]:
        """
        Complete OMR processing pipeline
        """

        img, gray, thresh = self.preprocess_image(image_path)


        circles = self.find_circles(gray)
        print(f"Detected {len(circles)} circles")


        bounding_boxes = self.create_bounding_boxes(circles, gray.shape)
        print(f"Created bounding boxes for {len(bounding_boxes)} questions")


        results = self.analyze_marking(gray, bounding_boxes)


        vis_img = self.visualize_results(img, bounding_boxes, results)

        return bounding_boxes, results, vis_img

    def print_results(self, results: Dict):
        """
        Print analysis results in a readable format, organized by batches
        """
        print("\n" + "="*60)
        print("OMR ANALYSIS RESULTS (Organized by Batches)")
        print("="*60)


        sorted_questions = sorted(results.keys(), key=lambda x: int(x[1:]))


        batches = {
            "1-10": [],
            "11-20": [],
            "21-30": [],
            "31-40": []
        }

        for question in sorted_questions:
            q_num = int(question[1:])
            if 1 <= q_num <= 10:
                batches["1-10"].append(question)
            elif 11 <= q_num <= 20:
                batches["11-20"].append(question)
            elif 21 <= q_num <= 30:
                batches["21-30"].append(question)
            elif 31 <= q_num <= 40:
                batches["31-40"].append(question)


        for batch_name, questions in batches.items():
            if questions:
                print(f"\n{'='*20} BATCH {batch_name} {'='*20}")

                for question in questions:
                    options = results[question]
                    print(f"\n{question}:")
                    marked_options = []

                    for option, data in options.items():
                        status = "✓ MARKED" if data['marked'] else "✗ unmarked"
                        intensity = data['intensity']
                        threshold_status = data['threshold_status']

                        print(f"  {option}: {status} (intensity: {intensity:.3f}, threshold: {threshold_status})")

                        if data['marked']:
                            marked_options.append(option)

                    if marked_options:
                        print(f"  → Answer(s): {', '.join(marked_options)}")
                    else:
                        print(f"  → No answer detected")

    def get_answer_summary(self, results: Dict) -> Dict:
        """
        Get a clean summary of all answers
        """
        summary = {}


        sorted_questions = sorted(results.keys(), key=lambda x: int(x[1:]))

        for question in sorted_questions:
            options = results[question]
            marked_options = [opt for opt, data in options.items() if data['marked']]

            if marked_options:
                summary[question] = marked_options[0] if len(marked_options) == 1 else marked_options
            else:
                summary[question] = "No Answer"

        return summary

    def load_answer_key(self, answer_key_input) -> Dict:
        """
        Load answer key from various input formats

        Args:
            answer_key_input: Can be:
                - Dictionary: {"Q1": "A", "Q2": "B", ...}
                - List: ["A", "B", "C", "D", ...] (assumes Q1, Q2, Q3, ...)
                - String: "ABCDABCD..." (assumes Q1=A, Q2=B, Q3=C, ...)
                - File path: path to text file with answers

        Returns:
            Dictionary with question keys and correct answers
        """
        answer_key = {}

        if isinstance(answer_key_input, dict):
            answer_key = answer_key_input

        elif isinstance(answer_key_input, list):
            for i, answer in enumerate(answer_key_input, 1):
                if answer.upper() in ['A', 'B', 'C', 'D']:
                    answer_key[f"Q{i}"] = answer.upper()

        elif isinstance(answer_key_input, str):
            if len(answer_key_input) > 50 or '/' in answer_key_input or '\\' in answer_key_input or answer_key_input.endswith('.txt'):
                try:
                    with open(answer_key_input, 'r') as f:
                        content = f.read().strip()
                        if '=' in content or ':' in content:
                            for line in content.split('\n'):
                                if '=' in line:
                                    q, a = line.split('=')
                                    answer_key[q.strip()] = a.strip().upper()
                                elif ':' in line:
                                    q, a = line.split(':')
                                    answer_key[q.strip()] = a.strip().upper()
                        else:
                            for i, char in enumerate(content, 1):
                                if char.upper() in ['A', 'B', 'C', 'D']:
                                    answer_key[f"Q{i}"] = char.upper()
                except FileNotFoundError:
                    print(f"Warning: Answer key file '{answer_key_input}' not found. Treating as answer string.")
                    for i, char in enumerate(answer_key_input, 1):
                        if char.upper() in ['A', 'B', 'C', 'D']:
                            answer_key[f"Q{i}"] = char.upper()
            else:
                for i, char in enumerate(answer_key_input, 1):
                    if char.upper() in ['A', 'B', 'C', 'D']:
                        answer_key[f"Q{i}"] = char.upper()

        return answer_key

    def compare_with_answer_key(self, student_answers: Dict, answer_key: Dict) -> Dict:
        """
        Compare student answers with the answer key

        Args:
            student_answers: Dictionary from get_answer_summary()
            answer_key: Dictionary with correct answers

        Returns:
            Dictionary with comparison results
        """
        comparison = {
            'correct': [],
            'incorrect': [],
            'unanswered': [],
            'multiple_marked': [],
            'score': 0,
            'total_questions': 0,
            'percentage': 0.0,
            'detailed_results': {}
        }

        all_questions = set(student_answers.keys()) | set(answer_key.keys())
        comparison['total_questions'] = len(all_questions)

        for question in sorted(all_questions, key=lambda x: int(x[1:]) if x[1:].isdigit() else 0):
            student_answer = student_answers.get(question, "No Answer")
            correct_answer = answer_key.get(question, "Unknown")

            result = {
                'student_answer': student_answer,
                'correct_answer': correct_answer,
                'status': '',
                'points': 0
            }

            if isinstance(student_answer, list):
                result['status'] = 'Multiple Marked'
                result['points'] = 0
                comparison['multiple_marked'].append(question)
            elif student_answer == "No Answer":
                result['status'] = 'Unanswered'
                result['points'] = 0
                comparison['unanswered'].append(question)
            elif correct_answer == "Unknown":
                result['status'] = 'No Answer Key'
                result['points'] = 0
            elif student_answer == correct_answer:
                result['status'] = 'Correct'
                result['points'] = 1
                comparison['correct'].append(question)
                comparison['score'] += 1
            else:
                result['status'] = 'Incorrect'
                result['points'] = 0
                comparison['incorrect'].append(question)

            comparison['detailed_results'][question] = result

        if comparison['total_questions'] > 0:
            comparison['percentage'] = (comparison['score'] / comparison['total_questions']) * 100

        return comparison

    def print_comparison_results(self, comparison: Dict, show_detailed: bool = True):
        """
        Print detailed comparison results
        """
        print("\n" + "="*80)
        print("OMR GRADING RESULTS")
        print("="*80)


        print(f"\nSCORE: {comparison['score']}/{comparison['total_questions']} ({comparison['percentage']:.1f}%)")
        print(f"Correct: {len(comparison['correct'])}")
        print(f"Incorrect: {len(comparison['incorrect'])}")
        print(f"Unanswered: {len(comparison['unanswered'])}")
        print(f"Multiple Marked: {len(comparison['multiple_marked'])}")


        percentage = comparison['percentage']
        if percentage >= 90:
            grade = "A+"
        elif percentage >= 85:
            grade = "A"
        elif percentage >= 80:
            grade = "A-"
        elif percentage >= 75:
            grade = "B+"
        elif percentage >= 70:
            grade = "B"
        elif percentage >= 65:
            grade = "B-"
        elif percentage >= 60:
            grade = "C+"
        elif percentage >= 55:
            grade = "C"
        elif percentage >= 50:
            grade = "C-"
        else:
            grade = "F"

        print(f"\nESTIMATED GRADE: {grade}")

        if show_detailed:

            print("\n" + "="*50)
            print("DETAILED RESULTS BY BATCH")
            print("="*50)


            batches = {"1-10": [], "11-20": [], "21-30": [], "31-40": []}

            for question in sorted(comparison['detailed_results'].keys(), key=lambda x: int(x[1:]) if x[1:].isdigit() else 0):
                q_num = int(question[1:]) if question[1:].isdigit() else 0
                if 1 <= q_num <= 10:
                    batches["1-10"].append(question)
                elif 11 <= q_num <= 20:
                    batches["11-20"].append(question)
                elif 21 <= q_num <= 30:
                    batches["21-30"].append(question)
                elif 31 <= q_num <= 40:
                    batches["31-40"].append(question)

            for batch_name, questions in batches.items():
                if questions:
                    print(f"\n{'='*15} BATCH {batch_name} {'='*15}")
                    batch_correct = 0
                    batch_total = len(questions)

                    for question in questions:
                        result = comparison['detailed_results'][question]
                        status_symbol = {
                            'Correct': '✓',
                            'Incorrect': '✗',
                            'Unanswered': '○',
                            'Multiple Marked': '◐',
                            'No Answer Key': '?'
                        }.get(result['status'], '?')

                        print(f"{question}: {result['student_answer']:>12} | Correct: {result['correct_answer']:>2} | {status_symbol} {result['status']}")

                        if result['status'] == 'Correct':
                            batch_correct += 1

                    batch_percentage = (batch_correct / batch_total) * 100 if batch_total > 0 else 0
                    print(f"Batch Score: {batch_correct}/{batch_total} ({batch_percentage:.1f}%)")


        if comparison['incorrect']:
            print(f"\nINCORRECT ANSWERS: {', '.join(comparison['incorrect'])}")

        if comparison['unanswered']:
            print(f"UNANSWERED: {', '.join(comparison['unanswered'])}")

        if comparison['multiple_marked']:
            print(f"MULTIPLE MARKED: {', '.join(comparison['multiple_marked'])}")

    def save_grading_report(self, comparison: Dict, student_answers: Dict, filename: str = "grading_report.txt"):
        """
        Save detailed grading report to file
        """
        with open(filename, 'w') as f:
            f.write("OMR GRADING REPORT\n")
            f.write("="*50 + "\n\n")

            f.write(f"Score: {comparison['score']}/{comparison['total_questions']} ({comparison['percentage']:.1f}%)\n")
            f.write(f"Correct: {len(comparison['correct'])}\n")
            f.write(f"Incorrect: {len(comparison['incorrect'])}\n")
            f.write(f"Unanswered: {len(comparison['unanswered'])}\n")
            f.write(f"Multiple Marked: {len(comparison['multiple_marked'])}\n\n")

            f.write("DETAILED RESULTS:\n")
            f.write("-" * 30 + "\n")

            for question in sorted(comparison['detailed_results'].keys(), key=lambda x: int(x[1:]) if x[1:].isdigit() else 0):
                result = comparison['detailed_results'][question]
                f.write(f"{question}: Student={result['student_answer']}, Correct={result['correct_answer']}, Status={result['status']}\n")

        print(f"\nDetailed grading report saved as '{filename}'")

    def process_omr_with_grading(self, image_path: str, answer_key_input) -> Tuple[Dict, Dict, Dict, np.ndarray]:
        """
        Complete OMR processing pipeline with grading
        """

        bounding_boxes, results, vis_img = self.process_omr_sheet(image_path)


        student_answers = self.get_answer_summary(results)


        answer_key = self.load_answer_key(answer_key_input)
        comparison = self.compare_with_answer_key(student_answers, answer_key)

        return bounding_boxes, results, comparison, vis_img


def main():

    detector = OMRDetector()


    detector.marking_threshold = 0.3

    image_path = "/content/IMG-20250803-WA0015.jpg"
    answer_key = {
        "Q1": "B", "Q2": "B", "Q3": "B", "Q4": "A", "Q5": "D",
        "Q6": "D", "Q7": "C", "Q8": "C", "Q9": "B", "Q10": "B",
        "Q11": "A", "Q12": "D", "Q13": "B", "Q14": "C", "Q15": "A",
        "Q16": "C", "Q17": "D", "Q18": "D", "Q19": "C", "Q20": "D",
        "Q21": "A", "Q22": "D", "Q23": "A", "Q24": "D", "Q25": "A",
        "Q26": "D", "Q27": "B", "Q28": "C", "Q29": "C", "Q30": "A",
        "Q31": "B", "Q32": "D", "Q33": "A", "Q34": "D", "Q35": "A",
        "Q36": "C", "Q37": "D", "Q38": "C", "Q39": "B", "Q40": "D"
    }


    try:

        bounding_boxes, results, comparison, visualization = detector.process_omr_with_grading(image_path, answer_key)


        print("\n" + "="*40)
        print("DETECTED ANSWERS")
        print("="*40)
        summary = detector.get_answer_summary(results)
        for question, answer in summary.items():
            print(f"{question}: {answer}")


        detector.print_comparison_results(comparison, show_detailed=True)


        detector.save_grading_report(comparison, summary, "grading_report.txt")


        cv2.imwrite("omr_graded_results.jpg", visualization)
        print(f"\nVisualization saved as 'omr_graded_results.jpg'")

    except Exception as e:
        print(f"Error processing OMR sheet: {e}")
        print("Please check:")
        print("1. Image path is correct")
        print("2. Image file exists and is readable")
        print("3. Image contains clear circular answer bubbles")
        print("4. Answer key format is correct")

if __name__ == "__main__":
    main()

